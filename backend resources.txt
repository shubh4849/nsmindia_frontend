Backend Endpoints:

---
### Routes
---

#### `src/routes/v1/file.route.js`
```javascript
const express = require('express');
const validate = require('../../middlewares/validate');
const fileValidation = require('../../validations/file.validation');
const fileController = require('../../controllers/file.controller');
const multer = require('multer');
const {fileTypes} = require('../../constants');
const router = express.Router();
const upload = multer({
  storage: multer.memoryStorage(),
  limits: {
    fileSize: 100 * 1024 * 1024,
  },
  fileFilter: (req, file, cb) => {
    if (fileTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error('File type not supported'), false);
    }
  },
});
router.post('/upload', upload.single('file'), fileController.uploadFile);

router.route('/').get(fileController.getFiles);

// Specific routes must be declared before generic parameterized routes
router.get('/search', fileController.searchFiles);
router.get('/count', fileController.getTotalFiles); // New route for total files count

router
  .route('/:fileId')
  .get(validate(fileValidation.getFile), fileController.getFile)
  .patch(validate(fileValidation.updateFile), fileController.updateFile)
  .delete(validate(fileValidation.deleteFile), fileController.deleteFile);

router.get('/:fileId/download', validate(fileValidation.getFile), fileController.downloadFile);
router.get('/:fileId/preview', validate(fileValidation.getFile), fileController.previewFile);

module.exports = router;
```

#### `src/routes/v1/folder.route.js`
```javascript
const express = require('express');
const validate = require('../../middlewares/validate');
const folderValidation = require('../../validations/folder.validation');
const folderController = require('../../controllers/folder.controller');

const router = express.Router();

router
  .route('/')
  .post(validate(folderValidation.createFolder), folderController.createFolder)
  .get(folderController.getFolders);

// Specific routes must be declared before generic parameterized routes
router.get('/tree', folderController.getFolderTree);
router.get('/count', folderController.getTotalFolders); // New route for total folders count

router
  .route('/:folderId')
  .get(validate(folderValidation.getFolder), folderController.getFolder)
  .patch(validate(folderValidation.updateFolder), folderController.updateFolder)
  .delete(validate(folderValidation.deleteFolder), folderController.deleteFolder);

router.get('/:folderId/contents', validate(folderValidation.getFolder), folderController.getFolderContents);
router.get('/:folderId/breadcrumb', validate(folderValidation.getFolder), folderController.getFolderBreadcrumb);
router.get('/:folderId/filtered', validate(folderValidation.getFolder), folderController.getFilteredFolderContents);

// New routes for direct child counts
router.get(
  '/:folderId/child-folders/count',
  validate(folderValidation.getFolder),
  folderController.getDirectChildFoldersCount
);
router.get(
  '/:folderId/child-files/count',
  validate(folderValidation.getFolder),
  folderController.getDirectChildFilesCount
);

module.exports = router;
```

#### `src/routes/v1/sse.route.js`
```javascript
const express = require('express');
const sseController = require('../../controllers/sse.controller');

const router = express.Router();

router.get('/upload-progress/:uploadId', sseController.getUploadProgress);
router.get('/folder-updates/:folderId', sseController.getFolderUpdates);

module.exports = router;
```

---
### Validations
---

#### `src/validations/file.validation.js`
```javascript
const Joi = require('joi');
const {objectId} = require('./custom.validation');

const createFile = {
  body: Joi.object().keys({
    name: Joi.string().required(),
    originalName: Joi.string().required(),
    filePath: Joi.string().required(),
    fileSize: Joi.number().required(),
    mimeType: Joi.string().required(),
    folderId: Joi.string().custom(objectId).required(),
    description: Joi.string(),
  }),
};

const getFile = {
  params: Joi.object().keys({
    fileId: Joi.string().custom(objectId),
  }),
};

const updateFile = {
  params: Joi.object().keys({
    fileId: Joi.required().custom(objectId),
  }),
  body: Joi.object().keys({
    name: Joi.string(),
    description: Joi.string(),
  }).min(1),
};

const deleteFile = {
  params: Joi.object().keys({
    fileId: Joi.string().custom(objectId),
  }),
};

const searchFiles = {
  query: Joi.object().keys({
    q: Joi.string(),
    folderId: Joi.string().custom(objectId),
    type: Joi.string(),
    name: Joi.string(),
    description: Joi.string(),
    dateFrom: Joi.string(),
    dateTo: Joi.string(),
    sortBy: Joi.string(),
    limit: Joi.number().integer().min(1).max(100).default(10),
    page: Joi.number().integer().min(1).default(1),
  }),
};

const getFiles = {
  query: Joi.object().keys({
    folderId: Joi.string().custom(objectId),
    name: Joi.string(),
    description: Joi.string(),
    dateFrom: Joi.string(),
    dateTo: Joi.string(),
    sortBy: Joi.string(),
    limit: Joi.number().integer().min(1).default(1),
    page: Joi.number().integer().min(1).default(1),
  }),
};

module.exports = {
  createFile,
  getFile,
  updateFile,
  deleteFile,
  searchFiles,
  getFiles,
};
```

#### `src/validations/folder.validation.js`
```javascript
const Joi = require('joi');
const {objectId} = require('./custom.validation');

const createFolder = {
  body: Joi.object().keys({
    name: Joi.string().required(),
    parentId: Joi.string().custom(objectId),
    description: Joi.string(),
    path: Joi.string().required(),
  }),
};

const getFolder = {
  params: Joi.object().keys({
    folderId: Joi.string().custom(objectId),
  }),
};

const updateFolder = {
  params: Joi.object().keys({
    folderId: Joi.required().custom(objectId),
  }),
  body: Joi.object().keys({
    name: Joi.string(),
    parentId: Joi.string().custom(objectId),
    description: Joi.string(),
    path: Joi.string(),
  }).min(1),
};

const deleteFolder = {
  params: Joi.object().keys({
    folderId: Joi.string().custom(objectId),
  }),
};

const getFolders = {
  query: Joi.object().keys({
    name: Joi.string(),
    parentId: Joi.string().custom(objectId).allow(null),
    sortBy: Joi.string(),
    limit: Joi.number().integer().min(1).default(1),
    page: Joi.number().integer().min(1).default(1),
  }),
};

module.exports = {
  createFolder,
  getFolder,
  updateFolder,
  deleteFolder,
  getFolders,
};
```

---
### Controllers (status wrapping + SSE init)
---

#### `src/controllers/file.controller.js`
```javascript
const httpStatus = require('http-status');
const pick = require('../utils/pick');
const ApiError = require('../utils/ApiError');
const catchAsync = require('../utils/catchAsync');
const {fileService, progressService} = require('../services');
const uuid = require('uuid');
const {fileTypes, ALL_ALLOWED_FILE_TYPES} = require('../constants');
const {getPaginateConfig} = require('../utils/queryPHandler');

const uploadFile = catchAsync(async (req, res) => {
  const uploadId = uuid.v4();
  if (!req.file) throw new ApiError(httpStatus.BAD_REQUEST, 'No file uploaded');
  if (!fileTypes.includes(req.file.mimetype)) {
    throw new ApiError(httpStatus.UNSUPPORTED_MEDIA_TYPE, `File type ${req.file.mimetype} is not supported. Allowed types: ${ALL_ALLOWED_FILE_TYPES.join(', ')}`);
  }
  // Initialize progress for SSE
  await progressService.updateUploadProgress(uploadId, 0, req.file.size, { fileName: req.file.originalname, status: 'uploading' });
  try {
    const file = await fileService.createFile({ buffer: req.file.buffer, originalName: req.file.originalname, mimeType: req.file.mimetype, fileSize: req.file.size, folderId: req.body.folderId });
    await progressService.updateUploadProgress(uploadId, req.file.size, req.file.size, { fileName: req.file.originalname, status: 'completed' });
    res.status(httpStatus.CREATED).send({ status: true, uploadId, file });
  } catch (err) {
    try { await progressService.updateUploadProgress(uploadId, 0, req.file.size, { fileName: req.file.originalname, status: 'failed' }); } catch {}
    throw err;
  }
});

const getFiles = catchAsync(async (req, res) => {
  const {filters, options} = getPaginateConfig(req.query);
  const result = await fileService.queryFiles(filters, options);
  res.send(result);
});

const getFile = catchAsync(async (req, res) => {
  const file = await fileService.getFileById(req.params.fileId);
  if (!file) {
    throw new ApiError(httpStatus.NOT_FOUND, 'File not found');
  }
  res.send(file);
});

const downloadFile = catchAsync(async (req, res) => {
  const file = await fileService.getFileById(req.params.fileId);
  if (!file) {
    throw new ApiError(httpStatus.NOT_FOUND, 'File not found');
  }
  res.redirect(file.filePath);
});

const previewFile = catchAsync(async (req, res) => {
  const file = await fileService.getFileById(req.params.fileId);
  if (!file) {
    throw new ApiError(httpStatus.NOT_FOUND, 'File not found');
  }
  res.redirect(file.filePath);
});

const updateFile = catchAsync(async (req, res) => {
  const file = await fileService.updateFileById(req.params.fileId, req.body);
  res.send(file);
});

const deleteFile = catchAsync(async (req, res) => {
  await fileService.deleteFileById(req.params.fileId);
  res.status(httpStatus.NO_CONTENT).send();
});

const searchFiles = catchAsync(async (req, res) => {
  const {q, ...otherQuery} = req.query;
  const {filters, options} = getPaginateConfig(otherQuery);

  const result = await fileService.getFilteredFiles({
    q,
    ...filters,
  }, options);

  res.json(result);
});

const getTotalFiles = catchAsync(async (req, res) => {
  const count = await fileService.getTotalFilesCount();
  res.status(httpStatus.OK).send({count});
});

module.exports = {
  uploadFile,
  getFiles,
  getFile,
  downloadFile,
  previewFile,
  updateFile,
  deleteFile,
  searchFiles,
  getTotalFiles,
};
```

#### `src/controllers/folder.controller.js`
```javascript
const httpStatus = require('http-status');
const pick = require('../utils/pick');
const ApiError = require('../utils/ApiError');
const catchAsync = require('../utils/catchAsync');
const {folderService, fileService} = require('../services');
const {getPaginateConfig} = require('../utils/queryPHandler');

const createFolder = catchAsync(async (req, res) => {
  const folder = await folderService.createFolder(req.body);
  res.status(httpStatus.CREATED).send(folder);
});

// includeChildCounts=true adds counts of direct child folders/files in each folder
const getFolders = catchAsync(async (req, res) => {
  const {includeChildCounts, ...rest} = req.query;
  const {filters, options} = getPaginateConfig(rest);

  if (includeChildCounts === 'true' || includeChildCounts === true) {
    options.pipeline = [
      {
        $lookup: {
          from: 'folders',
          let: {parent: '$_id'},
          pipeline: [{$match: {$expr: {$eq: ['$parentId', '$$parent']}}}, {$project: {_id: 1}}],
          as: 'childFoldersDocs',
        },
      },
      {
        $lookup: {
          from: 'files',
          let: {folder: '$_id'},
          pipeline: [{$match: {$expr: {$eq: ['$folderId', '$$folder']}}}, {$project: {_id: 1}}],
          as: 'childFilesDocs',
        },
      },
      {$addFields: {counts: {childFolders: {$size: '$childFoldersDocs'}, childFiles: {$size: '$childFilesDocs'}}}},
      {$project: {childFoldersDocs: 0, childFilesDocs: 0}},
    ];
  }

  const result = await folderService.queryFolders(filters, options);
  res.send(result);
});

const getFolder = catchAsync(async (req, res) => {
  const folder = await folderService.getFolderById(req.params.folderId);
  if (!folder) {
    throw new ApiError(httpStatus.NOT_FOUND, 'Folder not found');
  }
  res.send(folder);
});

const updateFolder = catchAsync(async (req, res) => {
  const folder = await folderService.updateFolderById(req.params.folderId, req.body);
  res.send(folder);
});

const deleteFolder = catchAsync(async (req, res) => {
  await folderService.cascadeDeleteFolder(req.params.folderId);
  res.status(httpStatus.NO_CONTENT).send();
});

const getFolderTree = catchAsync(async (req, res) => {
  const folders = await folderService.getAllFolders();
  const tree = folderService.buildTree(folders);
  res.send({ status: true, results: tree });
});

// Returns both folders and files under the given folderId
const getFolderContents = catchAsync(async (req, res) => {
  const {page = 1, limit = 10, name, description, dateFrom, dateTo} = req.query;
  const folders = await folderService.getFoldersByParentId(req.params.folderId);

  const filesPage = await fileService.getFilesByFolderId(
    req.params.folderId,
    {name, description, dateFrom, dateTo},
    {page, limit}
  );

  const files = filesPage.results || [];
  const totalFiles = filesPage.totalResults || 0;
  const totalPagesFiles = filesPage.totalPages || Math.ceil(totalFiles / parseInt(limit));

  res.json({
    status: true,
    folders,
    files,
    pagination: {
      page: parseInt(page),
      limit: parseInt(limit),
      totalFolders: folders.length,
      totalFiles: totalFiles,
      totalPagesFolders: Math.ceil(folders.length / limit),
      totalPagesFiles: totalPagesFiles,
    },
  });
});

const getFolderBreadcrumb = catchAsync(async (req, res) => {
  const breadcrumb = await folderService.getFolderBreadcrumb(req.params.folderId);
  res.send({ status: true, results: breadcrumb });
});

const getFilteredFolderContents = catchAsync(async (req, res) => {
  const {folderId} = req.params;
  const {q, type, dateFrom, dateTo, name, description, page = 1, limit = 10} = req.query;

  const folders = await folderService.getFoldersByParentId(folderId);
  const filesPage = await fileService.getFilteredFiles(
    {folderId, q, type, dateFrom, dateTo, name, description},
    {page, limit}
  );

  const files = filesPage.results || [];
  const totalFiles = filesPage.totalResults || 0;
  const totalPagesFiles = filesPage.totalPages || Math.ceil(totalFiles / parseInt(limit));

  res.json({
    status: true,
    folders,
    files,
    pagination: {
      page: parseInt(page),
      limit: parseInt(limit),
      totalFolders: folders.length,
      totalFiles: totalFiles,
      totalPagesFiles: totalPagesFiles,
    },
  });
});

const getTotalFolders = catchAsync(async (req, res) => {
  const count = await folderService.getTotalFoldersCount();
  res.status(httpStatus.OK).send({count});
});

const getDirectChildFoldersCount = catchAsync(async (req, res) => {
  const {folderId} = req.params;
  const count = await folderService.countChildFolders(folderId);
  res.status(httpStatus.OK).send({count});
});

const getDirectChildFilesCount = catchAsync(async (req, res) => {
  const {folderId} = req.params;
  const count = await fileService.countChildFiles(folderId);
  res.status(httpStatus.OK).send({count});
});

module.exports = {
  createFolder,
  getFolders,
  getFolder,
  updateFolder,
  deleteFolder,
  getFolderTree,
  getFolderContents,
  getFolderBreadcrumb,
  getFilteredFolderContents,
  getTotalFolders,
};

module.exports.getDirectChildFoldersCount = getDirectChildFoldersCount;
module.exports.getDirectChildFilesCount = getDirectChildFilesCount;
```

Example for GET /api/folders/:folderId/contents response:
```json
{
  "folders": [
    {
      "_id": "6897ade2f37b626b2aa223ee",
      "name": "Shubham's great grandson",
      "parentId": "6897a3e23c73a1737dbe4a91",
      "path": "Root/Shubham's great grandson/",
      "description": "this is Shubham's great grandson",
      "createdAt": "2025-08-09T20:21:54.201Z",
      "updatedAt": "2025-08-09T20:21:54.201Z",
      "__v": 0
    }
  ],
  "files": [
    {
      "_id": "6897abb7e84a92bed6964887",
      "name": "file",
      "originalName": "backend resources.txt",
      "filePath": "https://res.cloudinary.com/.../backend%20resources",
      "fileSize": 28905,
      "mimeType": "text/plain",
      "folderId": "6897a3e23c73a1737dbe4a91",
      "createdAt": "2025-08-09T20:12:39.210Z",
      "updatedAt": "2025-08-09T20:12:39.210Z",
      "__v": 0
    }
  ],
  "pagination": {
    "page": 1,
    "limit": 200,
    "totalFolders": 1,
    "totalFiles": 1,
    "totalPagesFolders": 1,
    "totalPagesFiles": 1
  }
}
```

Note for GET /api/folders:
- use `?includeChildCounts=true` to enrich each folder with `counts.childFolders` and `counts.childFiles`.

#### `src/controllers/sse.controller.js`
```javascript
const httpStatus = require('http-status');
const catchAsync = require('../utils/catchAsync');
const {progressService, sseService} = require('../services');

const getUploadProgress = catchAsync(async (req, res) => {
  res.writeHead(200, {'Content-Type': 'text/event-stream','Cache-Control': 'no-cache', Connection: 'keep-alive','Access-Control-Allow-Origin': '*'});
  const { uploadId } = req.params;
  const send = (event, data) => { if (event) res.write(`event: ${event}\n`); res.write(`data: ${JSON.stringify(data)}\n\n`); };
  const startedAt = Date.now();
  const maxWaitMs = 60 * 1000;
  const interval = setInterval(async () => {
    try {
      const progress = await progressService.getUploadProgressById(uploadId);
      if (progress) {
        send(null, { progress: progress.progress, status: progress.status, fileName: progress.fileName });
        if (progress.status === 'completed' || progress.status === 'failed') {
          clearInterval(interval);
          await progressService.cleanupUploadProgress(uploadId);
          res.end();
        }
      } else if (Date.now() - startedAt > maxWaitMs) {
        send('timeout', { status: 'failed', progress: 0 });
        clearInterval(interval); res.end();
      }
    } catch (e) { clearInterval(interval); res.end(); }
  }, 1000);
  req.on('close', () => { clearInterval(interval); res.end(); });
});

const getFolderUpdates = catchAsync(async (req, res) => {
  res.writeHead(200, {
    'Content-Type': 'text/event-stream',
    'Cache-Control': 'no-cache',
    Connection: 'keep-alive',
    'Access-Control-Allow-Origin': '*',
  });

  const {folderId} = req.params;

  const changeStream = sseService.getFolderChangeStream(folderId);

  changeStream.on('change', change => {
    res.write(`event: folderUpdate\ndata: ${JSON.stringify(change.fullDocument)}\n\n`);
  });

  req.on('close', () => {
    changeStream.close();
    res.end();
  });
});

module.exports = {
  getUploadProgress,
  getFolderUpdates,
};
```

---
### Controllers (auth, user)
---

#### `src/controllers/auth.controller.js`
```javascript
const httpStatus = require('http-status');
const catchAsync = require('../utils/catchAsync');
const {userService} = require('../services');
const {tokenService} = require('../services/token.service');
const {userValidation} = require('../validations');

const register = catchAsync(async (req, res) => {
  const user = await userService.createUser(req.body);
  const tokens = await tokenService.generateAuthTokens(user);
  res.status(httpStatus.CREATED).send({ status: true, user, tokens });
});

const login = catchAsync(async (req, res) => {
  const { email, password } = req.body;
  const user = await userService.loginUserWithEmailAndPassword(email, password);
  const tokens = await tokenService.generateAuthTokens(user);
  res.send({ status: true, user, tokens });
});

const logout = catchAsync(async (req, res) => {
  await tokenService.logout(req.body.refreshToken);
  res.status(httpStatus.NO_CONTENT).send({ status: true });
});

const refreshTokens = catchAsync(async (req, res) => {
  const tokens = await tokenService.refreshAuth(req.body.refreshToken);
  res.send({ status: true, ...tokens });
});

const forgotPassword = catchAsync(async (req, res) => {
  const resetPasswordToken = await tokenService.generateResetPasswordToken(req.body.email);
  res.send({ status: true, resetPasswordToken });
});

const resetPassword = catchAsync(async (req, res) => {
  await userService.resetPassword(req.query.token, req.body.password);
  res.send({ status: true });
});

const verifyEmail = catchAsync(async (req, res) => {
  await userService.verifyEmail(req.query.token);
  res.send({ status: true });
});

module.exports = {
  register,
  login,
  logout,
  refreshTokens,
  forgotPassword,
  resetPassword,
  verifyEmail,
};
```

#### `src/controllers/user.controller.js`
```javascript
const httpStatus = require('http-status');
const catchAsync = require('../utils/catchAsync');
const {userService} = require('../services');
const {tokenService} = require('../services/token.service');
const {userValidation} = require('../validations');

const getUsers = catchAsync(async (req, res) => {
  const users = await userService.queryUsers(req.query);
  res.send({ status: true, results: users });
});

const getUser = catchAsync(async (req, res) => {
  const user = await userService.getUserById(req.params.userId);
  if (!user) {
    throw new ApiError(httpStatus.NOT_FOUND, 'User not found');
  }
  res.send({ status: true, user });
});

const updateUser = catchAsync(async (req, res) => {
  const user = await userService.updateUserById(req.params.userId, req.body);
  res.send({ status: true, user });
});

const deleteUser = catchAsync(async (req, res) => {
  await userService.deleteUserById(req.params.userId);
  res.status(httpStatus.NO_CONTENT).send({ status: true });
});

module.exports = {
  getUsers,
  getUser,
  updateUser,
  deleteUser,
};
```

---
### Controllers (error)
---

#### `src/middlewares/error.js`
```javascript
const httpStatus = require('http-status');
const ApiError = require('../utils/ApiError');
const catchAsync = require('../utils/catchAsync');
const {logger} = require('../utils/logger');

const errorConverter = (err, req, res, next) => {
  let error = err;
  if (!(error instanceof ApiError)) {
    const statusCode = error.statusCode ? httpStatus.BAD_REQUEST : httpStatus.INTERNAL_SERVER_ERROR;
    const message = error.message || httpStatus[statusCode];
    error = new ApiError(statusCode, message, false, err.stack);
  }
  next(error);
};

const errorHandler = (err, req, res, next) => {
  let {statusCode, message} = err;
  if (statusCode === undefined) {
    statusCode = httpStatus.INTERNAL_SERVER_ERROR;
  }
  res.locals.errorMessage = err.message;

  const response = {
    code: statusCode,
    message,
  };

  if (process.env.NODE_ENV === 'development') {
    logger.error(err);
    response.stack = err.stack;
  }

  res.status(statusCode).send(response);
};

module.exports = {
  errorConverter,
  errorHandler,
};
```

---
### Models
---

#### `src/models/file.model.js`
```javascript
const mongoose = require('mongoose');
const fileSchema = new mongoose.Schema({
  name: String,
  originalName: String,
  filePath: String,
  publicId: String,
  key: String, // mirrors publicId for S3-like naming
  resourceType: String, // image | video | raw
  format: String,
  deliveryType: { type: String, default: 'upload' },
  fileSize: Number,
  mimeType: String,
  folderId: { type: mongoose.Schema.Types.ObjectId, ref: 'Folder' },
  description: String,
  createdAt: { type: Date, default: Date.now },
  updatedAt: { type: Date, default: Date.now },
});
fileSchema.index({ publicId: 1 });
fileSchema.index({ key: 1 });
const File = mongoose.models.File || mongoose.model('File', fileSchema, 'files');
module.exports = File;
```

#### `src/models/folder.model.js`
```javascript
const mongoose = require('mongoose');
const folderSchema = new mongoose.Schema({
  name: String,
  parentId: { type: mongoose.Schema.Types.ObjectId, ref: 'Folder', default: null },
  path: String,
  description: String,
  createdAt: { type: Date, default: Date.now },
  updatedAt: { type: Date, default: Date.now },
});
folderSchema.index({ name: 1, parentId: 1 }, { unique: true });
folderSchema.index({ path: 1 }, { unique: true });
const Folder = mongoose.models.Folder || mongoose.model('Folder', folderSchema, 'folders');
module.exports = Folder;
```

#### `src/models/uploadProgress.model.js`
```javascript
const mongoose = require('mongoose');
const uploadProgressSchema = new mongoose.Schema({
  uploadId: { type: String, required: true, unique: true },
  fileName: String,
  fileSize: Number,
  uploadedBytes: { type: Number, default: 0 },
  progress: { type: Number, default: 0 },
  status: { type: String, enum: ['uploading', 'completed', 'failed'], default: 'uploading' },
  createdAt: { type: Date, default: Date.now },
  updatedAt: { type: Date, default: Date.now },
});
uploadProgressSchema.index({ uploadId: 1 });
const UploadProgress = mongoose.models.UploadProgress || mongoose.model('UploadProgress', uploadProgressSchema, 'uploadProgress');
module.exports = UploadProgress;
```

---
### Microservices (Cloudinary)
---

#### `src/microservices/fileUpload.service.js`
```javascript
const cloudinary = require('cloudinary').v2;
const config = require('../config/config');
const {logger} = require('../utils/logger');

cloudinary.config({ cloud_name: config.cloudinary.cloudName, api_key: config.cloudinary.apiKey, api_secret: config.cloudinary.apiSecret, secure: true });
function sanitizeBaseName(name) {
  const lower = name.toLowerCase();
  const ext = lower.split('.').pop();
  const sanitized = lower.replace(/[^a-z0-9-.]/g, '-').replace(/-+/g, '-').replace(/^-|-$/g, '');
  return `${sanitized}-${Date.now()}.${ext}`;
}
const uploadFileToCloudinary = async ({ fileBuffer, folder, publicId, resourceType = 'auto' }) => new Promise((resolve, reject) => {
  cloudinary.uploader.upload_stream({ resource_type: resourceType, folder, public_id: publicId, use_filename: false, unique_filename: false, overwrite: true }, (error, result) => error ? reject(error) : resolve(result)).end(fileBuffer);
});
const deleteFileFromCloudinary = async (publicId, options={}) => cloudinary.uploader.destroy(publicId, options);
const deleteFolderIfEmpty = async (folder) => { try { return await cloudinary.api.delete_folder(folder); } catch (e) { return null; } };
module.exports = { sanitizeBaseName, uploadFileToCloudinary, deleteFileFromCloudinary, deleteFolderIfEmpty };
```

---
### Services
---

#### `src/services/file.service.js`
```javascript
const httpStatus = require('http-status');
const {File} = require('../models');
const ApiError = require('../utils/ApiError');
const {fileUploadService} = require('../microservices');

const createFile = async ({ buffer, originalName, mimeType, fileSize, folderId }) => {
  const folderPath = `files/${folderId || 'root'}`;
  const base = fileUploadService.sanitizeBaseName(originalName);
  const uniqueBase = `${uuidv4()}-${base}`;
  const uploadResult = await fileUploadService.uploadFileToCloudinary({ fileBuffer: buffer, folder: folderPath, publicId: uniqueBase, resourceType: 'auto' });
  return File.create({ name: base || originalName, originalName, filePath: uploadResult.secure_url, publicId: uploadResult.public_id, key: uploadResult.public_id, resourceType: uploadResult.resource_type, format: uploadResult.format, deliveryType: 'upload', fileSize, mimeType, folderId });
};

// Paginated query
const queryFiles = async (filters, options) => {
  const mongoFilters = {};
  if (filters.name) mongoFilters.name = new RegExp(filters.name, 'i');
  if (filters.description) mongoFilters.description = new RegExp(filters.description, 'i');
  if (filters.folderId) mongoFilters.folderId = filters.folderId;
  if (filters.mimeType) mongoFilters.mimeType = new RegExp(filters.mimeType, 'i');
  if (filters.dateFrom || filters.dateTo) {
    mongoFilters.createdAt = {};
    if (filters.dateFrom) mongoFilters.createdAt.$gte = new Date(filters.dateFrom);
    if (filters.dateTo) mongoFilters.createdAt.$lte = new Date(filters.dateTo);
  }
  return File.paginate(mongoFilters, options || {});
};

const getFileById = async id => File.findById(id);

const updateFileById = async (fileId, updateBody) => {
  const file = await getFileById(fileId);
  if (!file) throw new ApiError(httpStatus.NOT_FOUND, 'File not found');
  Object.assign(file, updateBody);
  await file.save();
  return file;
};

const deleteFileById = async (fileId) => {
  const file = await getFileById(fileId);
  if (!file) throw new ApiError(httpStatus.NOT_FOUND, 'File not found');
  let publicId = file.key || file.publicId; let resourceType = file.resourceType;
  if (!publicId || !resourceType) { const derived = deriveCloudinaryIdentifiers(file.filePath || ''); publicId = publicId || derived.publicId; resourceType = resourceType || derived.resourceType; }
  try { if (publicId) await fileUploadService.deleteFileFromCloudinary(publicId, { resource_type: resourceType || 'raw', type: 'upload', invalidate: true }); } catch {}
  await file.deleteOne();
  try { if (file.folderId && (await File.countDocuments({ folderId: file.folderId })) === 0) { const folderPath = `files/${file.folderId}`; await fileUploadService.deleteFolderIfEmpty(folderPath); } } catch {}
  return file;
};

const getFilesByFolderId = async (folderId, filterParams = {}, options = {}) => {
  return getFilteredFiles({...filterParams, folderId}, options);
};

// Filtered paginated query (supports q/name/description/type/date range)
const getFilteredFiles = async (filter, options) => {
  let query = {};
  if (filter.folderId) query.folderId = filter.folderId;
  if (filter.q) {
    query.$text = {$search: filter.q};
  } else {
    if (filter.name) query.name = new RegExp(filter.name, 'i');
    if (filter.description) query.description = new RegExp(filter.description, 'i');
  }
  if (filter.type) query.mimeType = new RegExp(filter.type, 'i');
  if (filter.dateFrom || filter.dateTo) {
    query.createdAt = {};
    if (filter.dateFrom) query.createdAt.$gte = new Date(filter.dateFrom);
    if (filter.dateTo) query.createdAt.$lte = new Date(filter.dateTo);
  }
  return File.paginate(query, options || {});
};

const getTotalFilesCount = async () => File.countDocuments();
const countChildFiles = async folderId => File.countDocuments({folderId});

module.exports = {
  createFile,
  queryFiles,
  getFileById,
  updateFileById,
  deleteFileById,
  getFilesByFolderId,
  getFilteredFiles,
  getTotalFilesCount,
  countChildFiles,
};
```

#### `src/services/folder.service.js`
```javascript
const httpStatus = require('http-status');
const {Folder, File} = require('../models');
const ApiError = require('../utils/ApiError');

const buildTree = (folders, parentId = null) => {
  const folderTree = [];
  folders.forEach(folder => {
    if (folder.parentId === parentId) {
      const children = buildTree(folders, folder._id);
      if (children.length > 0) {
        folder.children = children;
      }
      folderTree.push(folder);
    }
  });
  return folderTree;
};

const createFolder = async folderBody => {
  if (await Folder.isNameTaken(folderBody.name, folderBody.parentId)) {
    throw new ApiError(httpStatus.BAD_REQUEST, 'Folder with this name already exists in the parent folder');
  }
  return Folder.create(folderBody);
};

const queryFolders = async (filter, options) => {
  let query = {};

  if (filter.name) {
    query.name = new RegExp(filter.name, 'i');
  }
  if (filter.parentId === null || filter.parentId === undefined) {
    query.parentId = null;
  } else if (filter.parentId) {
    query.parentId = filter.parentId;
  }

  return Folder.paginate(query, options);
};

const getFolderById = async id => Folder.findById(id);

const updateFolderById = async (folderId, updateBody) => {
  const folder = await getFolderById(folderId);
  if (!folder) throw new ApiError(httpStatus.NOT_FOUND, 'Folder not found');
  if (updateBody.name && (await Folder.isNameTaken(updateBody.name, folder.parentId, folderId))) {
    throw new ApiError(httpStatus.BAD_REQUEST, 'Folder with this name already exists in the parent folder');
  }
  Object.assign(folder, updateBody);
  await folder.save();
  return folder;
};

const deleteFolderById = async folderId => {
  const folder = await getFolderById(folderId);
  if (!folder) throw new ApiError(httpStatus.NOT_FOUND, 'Folder not found');
  await folder.remove();
  return folder;
};

const getFolderBreadcrumb = async folderId => {
  const breadcrumb = await Folder.aggregate([
    {$match: {_id: folderId}},
    {
      $graphLookup: {
        from: 'folders',
        startWith: '$parentId',
        connectFromField: 'parentId',
        connectToField: '_id',
        as: 'path',
        maxDepth: 10,
      },
    },
    {$unwind: '$path'},
    {$project: {_id: '$path._id', name: '$path.name', parentId: '$path.parentId'}},
    {$sort: {'path._id': 1}},
  ]);
  return breadcrumb;
};

const cascadeDeleteFolder = async folderId => {
  const foldersToDelete = [folderId];
  let currentFolders = [folderId];
  while (currentFolders.length > 0) {
    const childFolders = await Folder.find({parentId: {$in: currentFolders}}).select('_id');
    const childFiles = await File.find({folderId: {$in: currentFolders}}).select('_id');

    if (childFolders.length > 0) {
      const childFolderIds = childFolders.map(folder => folder._id);
      foldersToDelete.push(...childFolderIds);
      currentFolders = childFolderIds;
    } else {
      currentFolders = [];
    }

    if (childFiles.length > 0) {
      const childFileIds = childFiles.map(file => file._id);
      await File.deleteMany({_id: {$in: childFileIds}});
    }
  }
  await Folder.deleteMany({_id: {$in: foldersToDelete}});
};

const getAllFolders = async () => Folder.find().select('_id name parentId path');
const getFoldersByParentId = async parentId => Folder.find({parentId});
const getTotalFoldersCount = async () => Folder.countDocuments();
const countChildFolders = async parentId => Folder.countDocuments({parentId});

module.exports = {
  buildTree,
  createFolder,
  queryFolders,
  getFolderById,
  updateFolderById,
  deleteFolderById,
  getFolderBreadcrumb,
  cascadeDeleteFolder,
  getAllFolders,
  getFoldersByParentId,
  getTotalFoldersCount,
  countChildFolders,
};
```

#### `src/services/progress.service.js`
```javascript
const {UploadProgress} = require('../models');

const updateUploadProgress = async (uploadId, uploadedBytes, totalBytes, meta = {}) => {
  const progress = totalBytes > 0 ? (uploadedBytes / totalBytes) * 100 : 0;
  const status = meta.status || (progress >= 100 ? 'completed' : 'uploading');
  const update = { uploadedBytes, progress, status, updatedAt: Date.now() };
  if (typeof totalBytes === 'number') update.fileSize = totalBytes;
  if (meta.fileName) update.fileName = meta.fileName;
  return UploadProgress.findByIdAndUpdate(uploadId, update, { new: true, upsert: true });
};

const getUploadProgressById = async uploadId => UploadProgress.findById(uploadId);

const cleanupUploadProgress = async uploadId => {
  await UploadProgress.findByIdAndDelete(uploadId);
};

module.exports = {
  updateUploadProgress,
  getUploadProgressById,
  cleanupUploadProgress,
};
```

#### `src/services/sse.service.js`
```javascript
const {Folder} = require('../models');

const getFolderChangeStream = folderId => {
  return Folder.watch([
    {$match: {'fullDocument.parentId': folderId}},
    {$match: {operationType: {$in: ['insert', 'update', 'delete']}}},
  ]);
};

module.exports = {
  getFolderChangeStream,
};
```

---
### Response shape (status flag)
---
- Success responses include `{ status: true, ... }` across controllers (file, folder, auth, user).
- Errors are shaped as `{ status: false, code, message, stack? }` via error middleware.

---
### Notes
---
- File size limit increased to 100MB.
- mp4 uploads accepted (`video/mp4`).
- Cloudinary publicId/key follow `files/<folderId>/<uuid>-<sanitized-name>`.
- Folder auto-cleanup: after last file in a folder is deleted, attempt Cloudinary `delete_folder(files/<folderId>)`.
- SSE upload-progress initialized at start; endpoint waits up to 60s for record and streams updates; closes on completed/failed.